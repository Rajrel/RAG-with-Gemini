{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a662844-c174-48bd-bcc5-0408660eebfb",
   "metadata": {},
   "source": [
    "## Query Construction \n",
    "With typical retrieval augmented generation (RAG), a user query is converted into a vector representation. This vector is then compared to vector representations of the source documents to find the most similar ones. This works fairly well for unstructured data (see our blog posts on Multi-Representation Indexing and Query Transformation), but what about structured data?\n",
    "\n",
    "Most data in the world has some structure. Much of this data lives in relational (e.g., SQL) or graph databases. And even unstructured data often associated structured metadata (e.g., things like the author, genre, data published, etc).\n",
    "\n",
    "For example, consider the query what are movies about aliens in the year 1980. There is a portion (aliens) that we may want to look up semantically, but also a component (\"year == 1980\") that we want to look up in an exact way.\n",
    "\n",
    "\n",
    "\n",
    "| Examples            | Data Source                     | References                 |\n",
    "|---------------------|---------------------------------|----------------------------|\n",
    "| Text-to-metadata-filter | Vectorstores                     | [Docs](https://python.langchain.com/v0.1/docs/modules/data_connection/retrievers/self_query/?ref=blog.langchain.dev#constructing-from-scratch-with-lcel)                       |\n",
    "| Text-to-SQL         | SQL DB                          |     [Docs](https://python.langchain.com/v0.1/docs/use_cases/sql/?ref=blog.langchain.dev)   |\n",
    "| Text-to-SQL+ Semantic | PGVector supported SQL DB         | [Cookbook](https://github.com/langchain-ai/langchain/blob/master/cookbook/retrieval_in_sql.ipynb?ref=blog.langchain.dev)                   |\n",
    "| Text-to-Cypher      | Graph databases                 | [Blog](https://blog.langchain.dev/implementing-advanced-retrieval-rag-strategies-with-neo4j)          |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98ce5954-25ea-49b2-a501-1e2614d94866",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, dotenv_values\n",
    "import google.generativeai as genai\n",
    "from IPython.display import Markdown, display\n",
    "import os \n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "os.getenv(\"GOOGLE_API_KEY\") \n",
    "my_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "genai.configure(api_key=my_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15e860c3-5125-4338-af83-a1d6c4d44033",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
    "\n",
    "## Call Embedding Model\n",
    "embedding = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")\n",
    "# LLM\n",
    "llm = ChatGoogleGenerativeAI(model= \"gemini-1.5-flash\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618aeed4-9294-4143-8251-34bdb671185d",
   "metadata": {},
   "source": [
    "\n",
    "```python \n",
    "        !pip install youtube-transcript-api -qU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5be06d1f-0545-41d9-aeff-8b324165583c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'pbAd8O1Lvm4',\n",
       " 'title': 'Self-reflective RAG with LangGraph: Self-RAG and CRAG',\n",
       " 'description': 'Unknown',\n",
       " 'view_count': 19975,\n",
       " 'thumbnail_url': 'https://i.ytimg.com/vi/pbAd8O1Lvm4/hq720.jpg',\n",
       " 'publish_date': '2024-02-07 00:00:00',\n",
       " 'length': 1058,\n",
       " 'author': 'LangChain'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import YoutubeLoader\n",
    "\n",
    "docs = YoutubeLoader.from_youtube_url(\n",
    "    \"https://www.youtube.com/watch?v=pbAd8O1Lvm4\", add_video_info=True\n",
    ").load()\n",
    "\n",
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dacc5f-9197-4f59-b85e-5cf1a8152ea9",
   "metadata": {},
   "source": [
    "Let’s assume we’ve built an index that:\n",
    "\n",
    "Allows us to perform unstructured search over the contents and title of each document\n",
    "And to use range filtering on view count, publication date, and length.\n",
    "We want to convert natural langugae into structured search queries.\n",
    "\n",
    "We can define a schema for structured search queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c0e7d2e-803c-4c52-8419-a45cd19fc729",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from typing import Literal, Optional, Tuple\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "class TutorialSearch(BaseModel):\n",
    "    \"\"\"Search over a database of tutorial videos about a software library.\"\"\"\n",
    "\n",
    "    content_search: str = Field(\n",
    "        ...,\n",
    "        description=\"Similarity search query applied to video transcripts.\",\n",
    "    )\n",
    "    title_search: str = Field(\n",
    "        ...,\n",
    "        description=(\n",
    "            \"Alternate version of the content search query to apply to video titles. \"\n",
    "            \"Should be succinct and only include key words that could be in a video \"\n",
    "            \"title.\"\n",
    "        ),\n",
    "    )\n",
    "    min_view_count: Optional[int] = Field(\n",
    "        None,\n",
    "        description=\"Minimum view count filter, inclusive. Only use if explicitly specified.\",\n",
    "    )\n",
    "    max_view_count: Optional[int] = Field(\n",
    "        None,\n",
    "        description=\"Maximum view count filter, exclusive. Only use if explicitly specified.\",\n",
    "    )\n",
    "    earliest_publish_date: Optional[datetime.date] = Field(\n",
    "        None,\n",
    "        description=\"Earliest publish date filter, inclusive. Only use if explicitly specified.\",\n",
    "    )\n",
    "    latest_publish_date: Optional[datetime.date] = Field(\n",
    "        None,\n",
    "        description=\"Latest publish date filter, exclusive. Only use if explicitly specified.\",\n",
    "    )\n",
    "    min_length_sec: Optional[int] = Field(\n",
    "        None,\n",
    "        description=\"Minimum video length in seconds, inclusive. Only use if explicitly specified.\",\n",
    "    )\n",
    "    max_length_sec: Optional[int] = Field(\n",
    "        None,\n",
    "        description=\"Maximum video length in seconds, exclusive. Only use if explicitly specified.\",\n",
    "    )\n",
    "\n",
    "    def pretty_print(self) -> None:\n",
    "        for field in self.__fields__:\n",
    "            if getattr(self, field) is not None and getattr(self, field) != getattr(\n",
    "                self.__fields__[field], \"default\", None\n",
    "            ):\n",
    "                print(f\"{field}: {getattr(self, field)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b590d701-2f0c-4fa9-bf3d-02be9c9b1e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system = \"\"\"You are an expert at converting user questions into database queries. \\\n",
    "You have access to a database of tutorial videos about a software library for building LLM-powered applications. \\\n",
    "Given a question, return a database query optimized to retrieve the most relevant results.\n",
    "\n",
    "If there are acronyms or words you are not familiar with, do not try to rephrase them.\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "structured_llm = llm.with_structured_output(TutorialSearch)\n",
    "query_analyzer = prompt | structured_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de4a9a13-5ae0-4669-b527-26987a27ae85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content_search: rag from scratch\n",
      "title_search: rag from scratch\n"
     ]
    }
   ],
   "source": [
    "query_analyzer.invoke({\"question\": \"rag from scratch\"}).pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b3821130-fc37-4b5c-b80e-b738e66190be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content_search: langchain\n",
      "title_search: langchain\n",
      "earliest_publish_date: 2023-01-01\n",
      "latest_publish_date: 2024-01-01\n"
     ]
    }
   ],
   "source": [
    "query_analyzer.invoke(\n",
    "    {\"question\": \"videos on langchain filter by publish_date = 2023\"}\n",
    ").pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3dbf865d-6dc4-4a97-a5dc-d76145b65fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content_search: multi-modal models agent\n",
      "title_search: multi-modal agent\n",
      "max_length_sec: 300\n"
     ]
    }
   ],
   "source": [
    "query_analyzer.invoke(\n",
    "    {\n",
    "        \"question\": \"how to use multi-modal models in an agent- filter vidoes under 5 minutes\"\n",
    "    }\n",
    ").pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311ba836-f603-43f9-9b19-6e360f0f8918",
   "metadata": {},
   "source": [
    "##### Alternative: Succinct schema\n",
    "If we have many filterable fields then having a verbose schema could harm performance, or may not even be possible given limitations on the size of function schemas. In these cases we can try more succinct query schemas that trade off some explicitness of direction for concision:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455b63b3-b497-4d08-b515-82ec4376eb00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
